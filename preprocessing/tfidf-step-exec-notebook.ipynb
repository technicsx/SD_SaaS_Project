{"cells":[{"cell_type":"markdown","source":"# ISW preprocessing","metadata":{"cell_id":"a78848a5d0fd4e34a5897a47dc230dcc","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":17,"fromCodePoint":0}],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":1},"deepnote_cell_type":"text-cell-h1"}},{"cell_type":"markdown","source":"### Install packages","metadata":{"cell_id":"6f16cd0deaeb4efd836f56e3018ad03d","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":7},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"%%bash \n# run pip upgrade if 'KeyboardInterrupt' error occurs\n# pip install --upgrade pip\n\npip install nltk num2words\npip install -U scikit-learn","metadata":{"cell_id":"9b1434b44565402a970783f71fd427f1","source_hash":"57d56a81","execution_start":1680019062987,"execution_millis":7289,"deepnote_app_coordinates":{"h":17,"w":12,"x":0,"y":13},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /shared-libs/python3.9/py/lib/python3.9/site-packages (3.7)\nRequirement already satisfied: num2words in /root/venv/lib/python3.9/site-packages (0.5.12)\nRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (4.64.1)\nRequirement already satisfied: click in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (8.1.3)\nRequirement already satisfied: joblib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from nltk) (2022.9.13)\nRequirement already satisfied: docopt>=0.6.2 in /root/venv/lib/python3.9/site-packages (from num2words) (0.6.2)\nRequirement already satisfied: scikit-learn in /root/venv/lib/python3.9/site-packages (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn) (1.9.3)\nRequirement already satisfied: numpy>=1.17.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn) (1.23.4)\nRequirement already satisfied: joblib>=1.1.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Import and download all dependecies","metadata":{"cell_id":"7133bbff0c7644cdac4b3394e5327dd8","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":31},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport pickle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport re\nfrom num2words import num2words\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nimport pandas as pd\nimport string\nfrom zipfile import ZipFile, ZipInfo\nfrom pathlib import Path\nimport os\n\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"cell_id":"8e138bae7b244bdea0d767dd645b62d8","source_hash":"ec535853","execution_start":1680019070283,"execution_millis":2920,"deepnote_app_coordinates":{"h":25,"w":12,"x":0,"y":37},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### Define preprocessing functions","metadata":{"cell_id":"3529039ed0544e6f984776537deef311","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":63},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"# Functions\ndef to_lower_case(text):\n  return \"\".join([i.lower() for i in text])\n\nstop_punctuation = string.punctuation\ndef remove_punctuation(text):\n  return \"\".join([i for i in text if i not in stop_punctuation])\n\ndef remove_long_dash(text):\n  return re.sub(r'â€”', ' ', text)\n\ndef remove_urls(text):\n  return re.sub(r'http\\S+', '', text)\n\ndef remove_one_letter_words(tokens):\n  return list(filter(lambda token: len(token) > 1, tokens))\n\ndef tokenize_text(text):\n  return nltk.tokenize.word_tokenize(text)\n\nstop_words = set(nltk.corpus.stopwords.words('english'))\navoid_stop_words = set([\"not\",\"n't\",\"no\"])\nstop_words = stop_words - avoid_stop_words\n\ndef remove_stop_words(tokens):\n  return [i for i in tokens if i not in stop_words]\n\ndef do_stemming(tokens):\n  ps = nltk.PorterStemmer()\n  return [ps.stem(word) for word in tokens]\n\ndef do_lemmatization(tokens):\n  wn = nltk.WordNetLemmatizer()\n  return [wn.lemmatize(word) for word in tokens]\n\ndef remove_numeric_words(text):\n  return re.sub(r'\\S*\\d+\\S*', '', text)\n\ndef convert_nums_to_words(data):\n  tokens = data\n  new_text = []\n  for word in tokens:\n    if word.isdigit():\n      if int(word)<1000000000:\n        word = num2words(word)\n      else: \n        word = \"\"\n    new_text.extend(tokenize_text(re.sub(\"(-|,\\s?)|\\s+\", \" \", word)))\n  return new_text\n\ndef do_preprocessing(data):\n  text_clean = data\n  text_clean = remove_urls(text_clean)\n  text_clean = remove_punctuation(text_clean)\n  text_clean = remove_long_dash(text_clean)\n  text_clean = to_lower_case(text_clean)\n  text_clean = remove_numeric_words(text_clean)\n  words = tokenize_text(text_clean)\n  words = remove_one_letter_words(words)\n  words = remove_stop_words(words)\n  lemmatized = do_lemmatization(words)\n  res = convert_nums_to_words(lemmatized)\n  return res","metadata":{"cell_id":"86fdbb97c0564339842d296aedb07a7d","source_hash":"bfe72237","execution_start":1680019073219,"execution_millis":5,"deepnote_app_coordinates":{"h":47,"w":12,"x":0,"y":69},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Zip opening","metadata":{"cell_id":"3adde034474b4e01b133850f0598de42","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":117},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"# specifying the zip file name\nfile_name = \"/work/isw_scrapping_res.zip\"\n\ndf = pd.DataFrame(columns = [\"Name\", \"Date\", \"Text\"])\nprint(\"Openning zip in read mode\")\n# opening the zip file in READ mode\nwith ZipFile(file_name, 'r') as zipfile:\n      for file in zipfile.infolist():\n        if not ZipInfo.is_dir(file):\n          filename = file.filename.rsplit('/', 1)[1].split('.')[0]\n          date = filename.replace(\"assessment-\", \"\")\n          text = zipfile.read(file.filename).decode('utf-8')\n          df = df.append({\"Name\": filename, \"Date\": date, \"Text\": text}, ignore_index = True)","metadata":{"cell_id":"9b0dd02d4a1d46c9910d60f25e24d79f","source_hash":"2e7a14d0","execution_start":1680019073228,"execution_millis":928,"deepnote_app_coordinates":{"h":13,"w":12,"x":0,"y":123},"deepnote_to_be_reexecuted":false,"deepnote_app_is_output_hidden":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Openning zip in read mode\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### TF-IDF creation","metadata":{"cell_id":"17b1138cf7c9457aa477a30ccadacbf0","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":137},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"print(\"Find tokens\")          \ndf[\"Tokens\"] = df[\"Text\"].apply(lambda d: \" \".join(do_preprocessing(d)))\n\nfilenames = df[\"Name\"]\ndates = df[\"Date\"]\n\nprint(\"Create vectors\")\ntfidf = TfidfVectorizer(smooth_idf=True,use_idf=True)\nvectors = tfidf.fit_transform(df[\"Tokens\"])\n\n# store content\nwith open(\"/work/results/tfidf.pkl\", \"wb\") as handle:\n  pickle.dump(tfidf, handle)\n\nfeature_names = tfidf.get_feature_names_out()\ndense = vectors.todense()\ndenselist = dense.tolist()\ndf = pd.DataFrame(denselist, columns=feature_names)\ndictionaries = df.to_dict(orient='records')\n\nprint(\"Into result\")\nres = __builtins__.zip(filenames, dates, dictionaries)\nres_df = pd.DataFrame(res, columns=[\"Name\",\"Date\",\"Keywords\"])\nres_df[\"Keywords\"] = res_df[\"Keywords\"].apply(lambda d: {k: v for k, v in d.items() if v > 0})\nres_df","metadata":{"cell_id":"09538d60d2d54f25bc752ee441583c16","source_hash":"33982a8a","execution_start":1680019074182,"execution_millis":95017,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_app_coordinates":{"h":44,"w":12,"x":0,"y":143},"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Find tokens\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Forming zip with .csv output","metadata":{"cell_id":"e242cea95d83442cb9f1ed85c15015ee","is_collapsed":false,"formattedRanges":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":188},"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"filename = \"tfidf-result\"\ncompression_options = dict(method='zip', archive_name=f'{filename}.csv')\nres_df.to_csv(f'/work/results/{filename}.zip', compression=compression_options, index=False)","metadata":{"cell_id":"aea029b8fb4c4edba10604e348a0b07e","source_hash":"779637eb","execution_start":1680018717924,"execution_millis":1068,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":194},"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=39e26e77-fa2f-42c6-b546-6cb73b166fc9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_app_layout":"article","deepnote_notebook_id":"06d8ca2a193745bfbc3fe24a0db1c199","deepnote_execution_queue":[]}}