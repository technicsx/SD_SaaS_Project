{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a78848a5d0fd4e34a5897a47dc230dcc",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 1
    },
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ],
    "is_collapsed": false
   },
   "source": [
    "# ISW preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7133bbff0c7644cdac4b3394e5327dd8",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 31
    },
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "### Import and download all dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8e138bae7b244bdea0d767dd645b62d8",
    "deepnote_app_coordinates": {
     "h": 25,
     "w": 12,
     "x": 0,
     "y": 37
    },
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2920,
    "execution_start": 1680019070283,
    "source_hash": "ec535853"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from text_preprocessing import (do_preprocessing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3adde034474b4e01b133850f0598de42",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 117
    },
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "### Reading target files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9b0dd02d4a1d46c9910d60f25e24d79f",
    "deepnote_app_coordinates": {
     "h": 13,
     "w": 12,
     "x": 0,
     "y": 123
    },
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 928,
    "execution_start": 1680019073228,
    "source_hash": "2e7a14d0"
   },
   "outputs": [],
   "source": [
    "from paths_full import *\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Text\"])\n",
    "\n",
    "df_list = []\n",
    "\n",
    "print(\"Reading folder contents\")\n",
    "for root, dirs, files in os.walk(ISW_SCRAPPING_FOLDER):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(root, filename), encoding=\"utf-8\") as file:\n",
    "                name = filename.split(\".\")[0]\n",
    "                date = filename.replace(\"assessment-\", \"\").replace(\".txt\", \"\")\n",
    "                text = file.read()\n",
    "                row_df = pd.DataFrame({\"Name\": [name], \"Date\": [date], \"Text\": [text]})\n",
    "                df_list.append(row_df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Successfully read the input data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "17b1138cf7c9457aa477a30ccadacbf0",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 137
    },
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "### TF-IDF creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "09538d60d2d54f25bc752ee441583c16",
    "deepnote_app_coordinates": {
     "h": 44,
     "w": 12,
     "x": 0,
     "y": 143
    },
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 95017,
    "execution_start": 1680019074182,
    "source_hash": "33982a8a"
   },
   "outputs": [],
   "source": [
    "print(\"Find tokens\")\n",
    "filteredDf = df[\"Text\"].apply(lambda d: \" \".join(do_preprocessing(d)))\n",
    "\n",
    "# To be uncommented if you want to see the most common words\n",
    "# print(\"Find most common words\")\n",
    "# all_words = []\n",
    "# for tokens in filteredDf:\n",
    "#     for word in tokens.split(\" \"):\n",
    "#         all_words.append(word)\n",
    "# all_words = nltk.FreqDist(all_words)\n",
    "# print(\"Top 30 frequenty used words: \")\n",
    "# print(all_words.most_common(30))\n",
    "\n",
    "frequent_words = {\n",
    "    \"russian\",\n",
    "    \"force\",\n",
    "    \"forces\",\n",
    "    \"ukrainian\",\n",
    "    \"ukraine\",\n",
    "    \"oblast\",\n",
    "    \"military\",\n",
    "    \"reported\",\n",
    "    \"effort\",\n",
    "    \"likely\",\n",
    "    \"claimed\",\n",
    "    \"russia\",\n",
    "    \"area\",\n",
    "    \"operation\",\n",
    "    \"continued\",\n",
    "    \"city\",\n",
    "    \"general\",\n",
    "    \"near\",\n",
    "    \"attack\",\n",
    "    \"official\",\n",
    "    \"staff\",\n",
    "    \"also\",\n",
    "    \"stated\",\n",
    "    \"source\",\n",
    "    \"oblast\",\n",
    "    \"pm\",\n",
    "    \"am\",\n",
    "    \"january\",\n",
    "    \"february\",\n",
    "    \"march\",\n",
    "    \"april\",\n",
    "    \"may\",\n",
    "    \"june\",\n",
    "    \"july\",\n",
    "    \"august\",\n",
    "    \"september\",\n",
    "    \"october\",\n",
    "    \"november\",\n",
    "    \"december\",\n",
    "}\n",
    "filteredDf = filteredDf.apply(\n",
    "    lambda d: \" \".join(w for w in d.split() if w not in frequent_words)\n",
    ")\n",
    "df[\"Tokens\"] = filteredDf\n",
    "\n",
    "filenames = df[\"Name\"]\n",
    "dates = df[\"Date\"]\n",
    "\n",
    "print(\"Create vectors\")\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, use_idf=True)\n",
    "vectors = tfidf.fit_transform(df[\"Tokens\"])\n",
    "\n",
    "# store content\n",
    "with open(\"results/tfidf.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(tfidf, handle)\n",
    "\n",
    "\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "dictionaries = df.to_dict(orient=\"records\")\n",
    "\n",
    "res = __builtins__.zip(filenames, dates, dictionaries)\n",
    "res_df = pd.DataFrame(res, columns=[\"Name\", \"Date\", \"Keywords\"])\n",
    "res_df[\"Keywords\"] = res_df[\"Keywords\"].apply(\n",
    "    lambda d: {k: v for k, v in d.items() if v > 0}\n",
    ")\n",
    "res_df[\"Keywords\"] = res_df[\"Keywords\"].apply(\n",
    "    lambda d: dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    ")\n",
    "\n",
    "res_df.to_csv(\"results/tfidf.csv\", index=False)\n",
    "print(\"Successfully written to .csv\")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "06d8ca2a193745bfbc3fe24a0db1c199",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
