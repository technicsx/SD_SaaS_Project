{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "\n",
    "# ENV[\"PYTHON\"] = \"C:\\\\Users\\\\lap2r\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "# Pkg.build(\"PyCall\")\n",
    "\n",
    "# Pkg.add(\"PyCall\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"DotEnv\")\n",
    "# Pkg.add(\"CSV\")\n",
    "# Pkg.add(\"Plots\")\n",
    "# Pkg.add(\"Dates\")\n",
    "# Pkg.add(\"Gadfly\")\n",
    "# Pkg.add(\"StatsPlots\")\n",
    "# Pkg.add(\"StatsBase\")\n",
    "# Pkg.add(\"JSON\")\n",
    "# Pkg.add(\"Makie\")\n",
    "\n",
    "# using Conda\n",
    "# Conda.add(\"nltk\")\n",
    "# Conda.add(\"num2words\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DotEnv\n",
    "\n",
    "DotEnv.config(\"../.path_env\", true)\n",
    "alarms_data_file_path = \"../\" * ENV[\"ALARMS_DATA_FILE\"]\n",
    "regions_data_file_path = \"../\" * ENV[\"REGIONS_DATA_FILE\"]\n",
    "weather_data_file_path = \"../\" * ENV[\"WEATHER_DATA_FILE\"]\n",
    "tfidf_csv_path = \"../\" * ENV[\"ISW_TF_IDF_RESULT\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "alarms = DataFrame(CSV.File(alarms_data_file_path))\n",
    "\n",
    "println(size(alarms))\n",
    "\n",
    "eltype.(eachcol(alarms))\n",
    "\n",
    "\n",
    "plot!(size=(800,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 10 rows of the alarms\n",
    "first(alarms, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe dataset\n",
    "describe(alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first event date\n",
    "println(\"first event date: \", minimum(alarms[!, :start]))\n",
    "\n",
    "# max event date\n",
    "println(\"max event date: \", maximum(alarms[!, :end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates\n",
    "using Statistics\n",
    "\n",
    "transform!(alarms, [:start, :end] => ((x, y) -> DateTime.(y, \"yyyy-mm-dd HH:MM:SS\") - DateTime.(x, \"yyyy-mm-dd HH:MM:SS\")) => :duration)\n",
    "\n",
    "transform!(alarms, :duration => (x -> Minute.(round.(Int, Dates.value.(x) / (1000 * 60)))) => :duration)\n",
    "\n",
    "println(\"minimum duration: \", minimum(alarms[!, :duration]))\n",
    "println(\"maximum duration: \", maximum(alarms[!, :duration]))\n",
    "\n",
    "sort!(alarms, :duration, rev=false)\n",
    "println(first(alarms, 10))\n",
    "sort!(alarms, :duration, rev=true)\n",
    "println(first(alarms, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize duration and corresponding counts using StatsPlots\n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "histogram(alarms[!, :duration], bins=100, xlabel=\"duration (minutes)\", ylabel=\"counts\", title=\"duration histogram\")\n",
    "\n",
    "# create a vector of durations\n",
    "durations = alarms.duration\n",
    "# count the frequency of each duration\n",
    "duration_counts = countmap(durations)\n",
    "# create a bar plot of the duration counts\n",
    "bar(duration_counts, xlabel=\"Duration (minutes)\", ylabel=\"Count\", title=\"Duration Counts\", legend=true, label=\"count\", color=\"white\", background_color=\"black\", grid=true)\n",
    "\n",
    "bar!(size=(800,600))\n",
    "\n",
    "\n",
    "# working:\n",
    "# using Plots\n",
    "# plot(alarms[!,:duration], seriestype=:histogram, bins=100, xlabel=\"duration (minutes)\", ylabel=\"counts\", title=\"duration histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_counts = countmap(alarms.duration)\n",
    "\n",
    "# duration_counts_df = DataFrame(duration_counts, [:duration, :count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = DataFrame(CSV.File(tfidf_csv_path))\n",
    "\n",
    "println(size(tfidf))\n",
    "println(names(tfidf))\n",
    "println(describe(tfidf))\n",
    "\n",
    "using JSON\n",
    "tfidf_keywords = tfidf[!, :Keywords]\n",
    "tfidf_keywords = [JSON.parse(replace(tfidf_keywords[i], \"'\" => \"\\\"\"), dicttype=Dict{String,Float64}) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "# append tfidf with :Count column which will contain number of items in :Keywords\n",
    "tfidf[!, :Count] = [length(tfidf_keywords[i]) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "# tfidf_keywords_count = Dict{String,Int64}()\n",
    "# for i in 1:length(tfidf_keywords)\n",
    "#     for (k, v) in tfidf_keywords[i]\n",
    "#         if haskey(tfidf_keywords_count, k)\n",
    "#             tfidf_keywords_count[k] += 1\n",
    "#         else\n",
    "#             tfidf_keywords_count[k] = 1\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "# tfidf_keywords_count\n",
    "\n",
    "\n",
    "# show :Name to count of :Keywords like \"assessment-2022-02-24\" - 4343 where 4343 is a count of items in :Keywords\n",
    "\n",
    "sort!(tfidf, [:Count], rev=true)\n",
    "# show :Name :Date and :Count columns\n",
    "tfidf[!, [:Name, :Date, :Count]]\n",
    "\n",
    "# visualize :Date and :Count using StatsPlots with x - :Date and y - :Count\n",
    "using Plots\n",
    "gr()\n",
    "# set limit to historgram\n",
    "\n",
    "start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "end_date = Date.(Dates.now())\n",
    "p = plot(tfidf[!, :Date], tfidf[!, :Count], seriestype=:scatter, xlabel=\"Date\", ylabel=\"Count\",\n",
    "        xlims=Dates.value.([start_date, end_date]), title=\"Date vs Unique words count\",\n",
    "        legend=true, label=\"count\", color=\"white\", background_color=\"black\",\n",
    "        grid=false);\n",
    "\n",
    "plot!(size=(800, 600))\n",
    "# savefig(p, \"plot.png\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFrequencyToDateFrame = DataFrame()\n",
    "# word_collection = Dict{String,Int64}()\n",
    "\n",
    "# for (root, dirs, files) in walkdir(\"../0_data_scrapping/results/isw/\")\n",
    "#     for file in files\n",
    "#         if endswith(file, \".txt\")\n",
    "#             file_path = joinpath(root, file)\n",
    "#             file_content = read(file_path, String)\n",
    "#             words_count = length(split(file_content))\n",
    "#             date = replace(file, \"assessment-\" => \"\")\n",
    "#             date = replace(date, \".txt\" => \"\")\n",
    "#             date = Date.(date, \"yyyy-mm-dd\")\n",
    "#             wordFrequencyToDateFrame = vcat(wordFrequencyToDateFrame, DataFrame(Date=date, Count=words_count))\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# call do_processing() function in 2_data_prepartion/text_preprocessing.py using pycall\n",
    "using PyCall\n",
    "\n",
    "println(PyCall.python)\n",
    "println(joinpath(@__DIR__, \"..\", \"2_data_preparation\"))\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\", \"2_data_preparation\"))\n",
    "text_processing = pyimport(\"text_preprocessing\")\n",
    "\n",
    "\n",
    "# sort!(wordFrequencyToDateFrame, :Count, rev=true)\n",
    "\n",
    "# println(describe(wordFrequencyToDateFrame))\n",
    "\n",
    "# using Plots\n",
    "# start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "# end_date = Date.(Dates.now())\n",
    "# p = plot(wordFrequencyToDateFrame[!, :Date], wordFrequencyToDateFrame[!, :Count], seriestype=:scatter, xlabel=\"Date\", ylabel=\"Count\",\n",
    "#     xlims=Dates.value.([start_date, end_date]), title=\"Date vs Total article words count\",\n",
    "#     legend=true, label=\"count\", color=\"white\", background_color=\"black\",\n",
    "#     grid=false);\n",
    "# println(p)\n",
    "# println(word_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "# 3×7 DataFrame\n",
    "#  Row │ variable  mean     min                                median   max                                nmissing  eltype   \n",
    "#      │ Symbol    Nothing  Any                                Nothing  Any                                Int64     DataType \n",
    "# ─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "#    1 │ Name               assessment-2022-02-24                       assessment-2023-04-03                     0  String31\n",
    "#    2 │ Date               2022-02-24                                  2023-04-03                                0  Date\n",
    "#    3 │ Keywords           {'agent': 0.20139877526758002, '…           {'znpp': 0.26604239982226846, 'c…         0  String\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
