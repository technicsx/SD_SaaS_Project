{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"PYTHON\"] = \"C:\\\\Users\\\\lap2r\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "ENV[\"PYTHON\"] = \"C:\\\\Users\\\\lap2r\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "\n",
    "# using Pkg\n",
    "# Pkg.add(\"PyCall\")\n",
    "# Pkg.build(\"PyCall\")\n",
    "\n",
    "\n",
    "# Pkg.add(\"OrderedCollections\")\n",
    "# Pkg.add(\"PrettyTables\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"DotEnv\")\n",
    "# Pkg.add(\"CSV\")\n",
    "# Pkg.add(\"Plots\")\n",
    "# Pkg.add(\"Dates\")\n",
    "# Pkg.add(\"Gadfly\")\n",
    "# Pkg.add(\"StatsPlots\")\n",
    "# Pkg.add(\"StatsBase\")\n",
    "# Pkg.add(\"JSON\")\n",
    "# Pkg.add(\"Makie\")\n",
    "\n",
    "\n",
    "# using Conda\n",
    "# Conda.add(\"nltk\")\n",
    "# Conda.add(\"num2words\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\"))\n",
    "paths_rel = pyimport(\"paths_rel\") \n",
    "\n",
    "alarms_data_file_path = \"../\" * paths_rel.REL_ALARMS_DATA_FILE\n",
    "regions_data_file_path = \"../\" * paths_rel.REL_REGIONS_DATA_FILE\n",
    "weather_data_file_path = \"../\" * paths_rel.REL_WEATHER_DATA_FILE\n",
    "tfidf_csv_path = \"../\" * paths_rel.REL_ISW_TF_IDF_RESULT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alarms dataset analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Viewing dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using StatsPlots\n",
    "\n",
    "alarms = DataFrame(CSV.File(alarms_data_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eltype.(eachcol(alarms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(alarms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysing dataset contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first event date\n",
    "println(\"First event date: \", minimum(alarms[!, :start]))\n",
    "\n",
    "# max event date\n",
    "println(\"Latest event date: \", maximum(alarms[!, :end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates\n",
    "using Statistics\n",
    "\n",
    "transform!(alarms, [:start, :end] => ((x, y) -> DateTime.(y, \"yyyy-mm-dd HH:MM:SS\") - DateTime.(x, \"yyyy-mm-dd HH:MM:SS\")) => :duration)\n",
    "\n",
    "transform!(alarms, :duration => (x -> Minute.(round.(Int, Dates.value.(x) / (1000 * 60)))) => :duration)\n",
    "\n",
    "println(\"minimum duration: \", minimum(alarms[!, :duration]))\n",
    "println(\"maximum duration: \", maximum(alarms[!, :duration]))\n",
    "\n",
    "sort!(alarms, :duration, rev=false)\n",
    "println(\"Sorted by minimum duration:\")\n",
    "println(first(alarms, 10))\n",
    "println(\"Sorted by maximum duration:\")\n",
    "sort!(alarms, :duration, rev=true)\n",
    "println(first(alarms, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize duration and corresponding counts using StatsPlots\n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "histogram(alarms[!, :duration], bins=100, xlabel=\"duration (minutes)\", ylabel=\"counts\", title=\"duration histogram\")\n",
    "\n",
    "# create a vector of durations\n",
    "durations = alarms.duration\n",
    "# count the frequency of each duration\n",
    "duration_counts = countmap(durations)\n",
    "# create a bar plot of the duration counts\n",
    "bar(duration_counts, xlabel=\"Duration (minutes)\", ylabel=\"Count\", title=\"Duration Counts\", legend=true, label=\"count\", color=\"red\", background_color=\"white\", linecolor=\"red\", grid=true)\n",
    "\n",
    "bar!(size=(800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_counts = countmap(alarms.duration)\n",
    "\n",
    "# convert dictionary to double array\n",
    "duration_counts = [k => v for (k, v) in duration_counts]\n",
    "duration_counts = sort(duration_counts, by=x->x[2], rev=true)\n",
    "duration_counts = duration_counts[1:50]\n",
    "\n",
    "# take each pair and seprate them into 2 arrays first value of pair to first array and second value of pair to second array\n",
    "duration, counts  = [x[1] for x in duration_counts], [x[2] for x in duration_counts]\n",
    "# create dataframe from items\n",
    "duration_counts = DataFrame(duration=duration, counts=counts)\n",
    "\n",
    "# visualize most popular duration of alarms using Cairo\n",
    "using Cairo\n",
    "using Gadfly\n",
    "using Colors\n",
    "using ColorSchemes\n",
    "# create a bar plot of the duration counts\n",
    "p = plot(duration_counts, x=\"duration\", y=\"counts\", Geom.bar, Scale.color_discrete_manual(\"red\"), Guide.xlabel(\"Duration (minutes)\"), Guide.ylabel(\"Count\"), Guide.title(\"Duration Counts\"), Theme(default_color=\"red\", key_position=:none, panel_fill=\"white\", panel_stroke=\"red\", minor_label_font_size=10pt, major_label_font_size=10pt, key_label_font_size=10pt, point_size=1mm, line_width=1mm, grid_line_width=1mm, grid_line_style=:dash, minor_label_color=\"red\", major_label_color=\"red\", key_label_color=\"red\", minor_label_font=\"Arial\", major_label_font=\"Arial\", key_label_font=\"Arial\"), Coord.cartesian(xmin=0, xmax=50, ymin=0, ymax=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = DataFrame(CSV.File(tfidf_csv_path))\n",
    "\n",
    "println(size(tfidf))\n",
    "println(names(tfidf))\n",
    "println(describe(tfidf))\n",
    "\n",
    "using JSON\n",
    "tfidf_keywords = tfidf[!, :Keywords]\n",
    "tfidf_keywords = [JSON.parse(replace(tfidf_keywords[i], \"'\" => \"\\\"\"), dicttype=Dict{String,Float64}) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "# append tfidf with :Count column which will contain number of items in :Keywords\n",
    "tfidf[!, :Count] = [length(tfidf_keywords[i]) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "# tfidf_keywords_count = Dict{String,Int64}()\n",
    "# for i in 1:length(tfidf_keywords)\n",
    "#     for (k, v) in tfidf_keywords[i]\n",
    "#         if haskey(tfidf_keywords_count, k)\n",
    "#             tfidf_keywords_count[k] += 1\n",
    "#         else\n",
    "#             tfidf_keywords_count[k] = 1\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "# tfidf_keywords_count\n",
    "\n",
    "\n",
    "# show :Name to count of :Keywords like \"assessment-2022-02-24\" - 4343 where 4343 is a count of items in :Keywords\n",
    "\n",
    "sort!(tfidf, [:Count], rev=true)\n",
    "# show :Name :Date and :Count columns\n",
    "tfidf[!, [:Name, :Date, :Count]]\n",
    "\n",
    "# visualize :Date and :Count using StatsPlots with x - :Date and y - :Count\n",
    "using Plots\n",
    "gr()\n",
    "# set limit to historgram\n",
    "\n",
    "start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "end_date = Date.(Dates.now())\n",
    "p = plot(tfidf[!, :Date], tfidf[!, :Count], seriestype=:scatter, xlabel=\"Date\", ylabel=\"Count\",\n",
    "        xlims=Dates.value.([start_date, end_date]), title=\"Date vs Unique words count\",\n",
    "        legend=true, label=\"count\", color=\"white\", background_color=\"black\",\n",
    "        grid=false);\n",
    "\n",
    "plot!(size=(800, 600))\n",
    "# savefig(p, \"plot.png\")\n",
    "p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISW Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFrequencyToDateFrame = DataFrame()\n",
    "# word_collection = Dict{String,Int64}()\n",
    "\n",
    "file_contents = \"\"\n",
    "for (root, dirs, files) in walkdir(\"../0_data_scrapping/results/isw/\")\n",
    "    for file in files\n",
    "        if endswith(file, \".txt\")\n",
    "            file_path = joinpath(root, file)\n",
    "            file_content = read(file_path, String)\n",
    "            file_contents = file_contents * \" \" * file_content\n",
    "\n",
    "            words_count = length(split(file_content))\n",
    "            date = replace(file, \"assessment-\" => \"\")\n",
    "            date = replace(date, \".txt\" => \"\")\n",
    "            date = Date.(date, \"yyyy-mm-dd\")\n",
    "            wordFrequencyToDateFrame = vcat(wordFrequencyToDateFrame, DataFrame(Date=date, Count=words_count))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# call do_processing() function in 2_data_prepartion/text_preprocessing.py using pycall\n",
    "\n",
    "# println(PyCall.python)\n",
    "\n",
    "# println(joinpath(@__DIR__, \"..\", \"2_data_preparation\"))\n",
    "\n",
    "\n",
    "\n",
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\", \"2_data_preparation\"))\n",
    "text_processing = pyimport(\"text_preprocessing\")\n",
    "file_contents = text_processing.do_preprocessing(file_contents)\n",
    "\n",
    "\n",
    "\n",
    "wordFrequency = countmap(file_contents)\n",
    "wordFrequencyToDateFrame = DataFrame(wordFrequency)\n",
    "# set name for dataframe\n",
    "rename!(wordFrequencyToDateFrame)\n",
    "# wordFrequencyToDateFrame\n",
    "describe(wordFrequencyToDateFrame)\n",
    "\n",
    "\n",
    "\n",
    "using OrderedCollections\n",
    "\n",
    "od = OrderedDict(wordFrequency)\n",
    "od_vector = sort!(od; byvalue=true, rev=true)\n",
    "\n",
    "\n",
    "od_vector = first(od_vector, 100)\n",
    "od_vector = map(x -> [x.first, string(x.second)], od_vector)\n",
    "\n",
    "words_for_table = map(x -> x[1], od_vector)\n",
    "counts_for_table = map(x -> x[2], od_vector)\n",
    "\n",
    "Base.displaysize(x::DataFrame) = (100, 100)\n",
    "dadasdasd = DataFrame(Word=words_for_table, Count=counts_for_table)\n",
    "show(dadasdasd, allrows=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Plots\n",
    "# Plots.plot(words_for_table, counts_for_table)\n",
    "\n",
    "\n",
    "\n",
    "# visualize this Vector{Vector{Any}} (od_vector)\n",
    "# using PrettyTables\n",
    "# pretty_table(od_vector)\n",
    "\n",
    "\n",
    "\n",
    "# # visualize it\n",
    "# using Plots\n",
    "\n",
    "# sortedWordFrequency = sort(collect(wordFrequency), by=x->x[2], rev=true)\n",
    "# arrr = map(x -> [x.first, x.second], sortedWordFrequency)\n",
    "\n",
    "# display large table of first 50 words in wordFrequency\n",
    "\n",
    "\n",
    "\n",
    "# convert it to dataframe\n",
    "# wordFrequencyToDateFrame = DataFrame(wordFrequency)\n",
    "# sort by :Count\n",
    "# sort!(wordFrequencyToDateFrame, :Count, rev=true)\n",
    "\n",
    "\n",
    "# using PrettyTables\n",
    "# # Sort the dictionary by keys\n",
    "# sorted_keys = sort(collect(keys(wordFrequency)))\n",
    "# sorted_values = [wordFrequency[k] for k in sorted_keys]\n",
    "# pretty_table([sorted_keys sorted_values], [\"Key\", \"Value\"])\n",
    "# # Sort the dictionary by values\n",
    "# sorted_pairs = sort(collect(wordFrequency), by = x -> x[2])\n",
    "# pretty_table(sorted_pairs, [\"Key\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "# 3×7 DataFrame\n",
    "#  Row │ variable  mean     min                                median   max                                nmissing  eltype   \n",
    "#      │ Symbol    Nothing  Any                                Nothing  Any                                Int64     DataType \n",
    "# ─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "#    1 │ Name               assessment-2022-02-24                       assessment-2023-04-03                     0  String31\n",
    "#    2 │ Date               2022-02-24                                  2023-04-03                                0  Date\n",
    "#    3 │ Keywords           {'agent': 0.20139877526758002, '…           {'znpp': 0.26604239982226846, 'c…         0  String\n",
    "\n",
    "# sort it\n",
    "\n",
    "\n",
    "# sort!(wordFrequencyToDateFrame, :Count, rev=true)\n",
    "\n",
    "# println(describe(wordFrequencyToDateFrame))\n",
    "\n",
    "# using Plots\n",
    "# start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "# end_date = Date.(Dates.now())\n",
    "# p = plot(wordFrequencyToDateFrame[!, :Date], wordFrequencyToDateFrame[!, :Count], seriestype=:scatter, xlabel=\"Date\", ylabel=\"Count\",\n",
    "#     xlims=Dates.value.([start_date, end_date]), title=\"Date vs Total article words count\",\n",
    "#     legend=true, label=\"count\", color=\"white\", background_color=\"black\",\n",
    "#     grid=false);\n",
    "# println(p)\n",
    "# println(word_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
