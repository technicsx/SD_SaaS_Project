{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = DataFrame(CSV.File(tfidf_csv_path))\n",
    "\n",
    "println(size(tfidf))\n",
    "println(names(tfidf))\n",
    "println(describe(tfidf))\n",
    "\n",
    "using JSON\n",
    "tfidf_keywords = tfidf[!, :Keywords]\n",
    "tfidf_keywords = [JSON.parse(replace(tfidf_keywords[i], \"'\" => \"\\\"\"), dicttype=Dict{String,Float64}) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "tfidf[!, :Count] = [length(tfidf_keywords[i]) for i in 1:length(tfidf_keywords)]\n",
    "sort!(tfidf, [:Count], rev=true)\n",
    "\n",
    "\n",
    "start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "end_date = Date.(Dates.now())\n",
    "\n",
    "p = plot(\n",
    "        tfidf[!, :Date],\n",
    "        tfidf[!, :Count],\n",
    "        seriestype=:scatter,\n",
    "        xlabel=\"Date\",\n",
    "        ylabel=\"Count\",\n",
    "        xlims=Dates.value.([start_date, end_date]),\n",
    "        title=\"Date vs Unique words count\",\n",
    "        legend=true,\n",
    "        label=\"count\",\n",
    "        grid=false,\n",
    "        size=(1200, 800),\n",
    ");\n",
    "\n",
    "xticks!(p, Dates.value.([start_date:Dates.Month(1):end_date;]), Dates.format.([start_date:Dates.Month(1):end_date;], \"yyyy-mm\"))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFrequencyToDateFrame = DataFrame()\n",
    "# word_collection = Dict{String,Int64}()\n",
    "\n",
    "file_contents = \"\"\n",
    "for (root, dirs, files) in walkdir(\"../0_data_scrapping/results/isw/\")\n",
    "    for file in files\n",
    "        if endswith(file, \".txt\")\n",
    "            file_path = joinpath(root, file)\n",
    "            file_content = read(file_path, String)\n",
    "            file_contents = file_contents * \" \" * file_content\n",
    "\n",
    "            words_count = length(split(file_content))\n",
    "            date = replace(file, \"assessment-\" => \"\")\n",
    "            date = replace(date, \".txt\" => \"\")\n",
    "            date = Date.(date, \"yyyy-mm-dd\")\n",
    "            wordFrequencyToDateFrame = vcat(wordFrequencyToDateFrame, DataFrame(Date=date, Count=words_count))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# call do_processing() function in 2_data_prepartion/text_preprocessing.py using pycall\n",
    "\n",
    "# println(PyCall.python)\n",
    "\n",
    "# println(joinpath(@__DIR__, \"..\", \"2_data_preparation\"))\n",
    "\n",
    "\n",
    "\n",
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\", \"1_data_preparation\"))\n",
    "text_processing = pyimport(\"text_preprocessing\")\n",
    "file_contents = text_processing.do_preprocessing(file_contents)\n",
    "\n",
    "\n",
    "\n",
    "wordFrequency = countmap(file_contents)\n",
    "wordFrequencyToDateFrame = DataFrame(wordFrequency)\n",
    "# set name for dataframe\n",
    "rename!(wordFrequencyToDateFrame)\n",
    "# wordFrequencyToDateFrame\n",
    "describe(wordFrequencyToDateFrame)\n",
    "\n",
    "\n",
    "\n",
    "using OrderedCollections\n",
    "\n",
    "od = OrderedDict(wordFrequency)\n",
    "od_vector = sort!(od; byvalue=true, rev=true)\n",
    "\n",
    "\n",
    "od_vector = first(od_vector, 100)\n",
    "od_vector = map(x -> [x.first, string(x.second)], od_vector)\n",
    "\n",
    "words_for_table = map(x -> x[1], od_vector)\n",
    "counts_for_table = map(x -> x[2], od_vector)\n",
    "\n",
    "Base.displaysize(x::DataFrame) = (100, 100)\n",
    "dadasdasd = DataFrame(Word=words_for_table, Count=counts_for_table)\n",
    "dadasdasd.Count = map(x -> parse(Int64, x), dadasdasd.Count)\n",
    "show(dadasdasd, allrows=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dadasdasd.Count to Int64\n",
    "\n",
    "# visualize dadasdasd\n",
    "using Printf\n",
    "\n",
    "bar(\n",
    "    dadasdasd.Word,\n",
    "    dadasdasd.Count,\n",
    "    xlabel=\"Word\",\n",
    "    ylabel=\"Count\",\n",
    "    title=\"Word frequency\",\n",
    "    label=\"Number of occurances\",\n",
    "    xrotation=90,\n",
    "    bar_width=0.3,\n",
    "    xticks=:all,\n",
    "    yticks=0:1000:50000,\n",
    "    yrotation=0,\n",
    "    yformatter=y -> @sprintf(\"%d\", y),\n",
    "    aspect_ratio=:none,\n",
    "    size=(1500, 1000),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
