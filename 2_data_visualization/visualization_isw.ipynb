{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"PYTHON\"] = \"C:\\\\Users\\\\lap2r\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "ENV[\"PYTHON\"] = \"C:\\\\Users\\\\lap2r\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\"))\n",
    "paths_rel = pyimport(\"paths_rel\")\n",
    "\n",
    "tfidf_csv_path = \"../\" * paths_rel.REL_ISW_TF_IDF_RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS_DEFAULTS = Dict(:dpi => 600)\n",
    "\n",
    "# https://docs.juliaplots.org/latest/generated/attributes_axis/\n",
    "# https://docs.juliaplots.org/latest/generated/attributes_plot/\n",
    "# https://docs.juliaplots.org/latest/generated/attributes_subplot/\n",
    "\n",
    "using Plots.PlotMeasures\n",
    "\n",
    "default(\n",
    "    legend=true,\n",
    "    left_margin=5mm,\n",
    "    right_margin=5mm,\n",
    "    top_margin=5mm,\n",
    "    bottom_margin=5mm,\n",
    "    xrotation=90,\n",
    "    draw_arrow=true,\n",
    "    grid=false,\n",
    "    minorgrid=false,\n",
    "    dpi=600,\n",
    "    size=(800, 800),\n",
    "    color=RGB(250 / 255, 135 / 255, 117 / 255),\n",
    "    linecolor=RGB(250 / 255, 135 / 255, 117 / 255),\n",
    "    markerstrokecolor=RGB(250 / 255, 135 / 255, 117 / 255),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "tfidf = DataFrame(CSV.File(tfidf_csv_path))\n",
    "\n",
    "println(size(tfidf))\n",
    "println(names(tfidf))\n",
    "println(describe(tfidf))\n",
    "\n",
    "using JSON\n",
    "tfidf_keywords = tfidf[!, :Keywords]\n",
    "tfidf_keywords = [JSON.parse(replace(tfidf_keywords[i], \"'\" => \"\\\"\"), dicttype=Dict{String,Float64}) for i in 1:length(tfidf_keywords)]\n",
    "\n",
    "tfidf[!, :Count] = [length(tfidf_keywords[i]) for i in 1:length(tfidf_keywords)]\n",
    "sort!(tfidf, [:Count], rev=true)\n",
    "\n",
    "using Dates\n",
    "start_date = Date.(\"2022-02-01\", \"yyyy-mm-dd\")\n",
    "end_date = Date.(Dates.now())\n",
    "\n",
    "using Plots\n",
    "p = plot(\n",
    "        tfidf[!, :Date],\n",
    "        tfidf[!, :Count],\n",
    "        seriestype=:scatter,\n",
    "        xlabel=\"\\nDate\\n\",\n",
    "        ylabel=\"Count\",\n",
    "        xlims=Dates.value.([start_date, end_date]),\n",
    "        title=\"\\nUnique words per day (report)\\nin calculated TFIDF\\n\",\n",
    "        legend=true,\n",
    "        label=\"Count\",\n",
    "        grid=false,\n",
    "        size=(1200, 800),\n",
    ");\n",
    "\n",
    "xticks!(p, Dates.value.([start_date:Dates.Month(1):end_date;]), Dates.format.([start_date:Dates.Month(1):end_date;], \"yyyy-mm\"))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFrequencyToDateFrame = DataFrame()\n",
    "\n",
    "\n",
    "allFilenamesV = []\n",
    "allWordsInArticle = Dict{Date,Int64}()\n",
    "\n",
    "file_contents = \"\"\n",
    "for (root, dirs, files) in walkdir(\"../0_data_scrapping/results/isw/\")\n",
    "    for file in files\n",
    "        if endswith(file, \".txt\")\n",
    "            file_path = joinpath(root, file)\n",
    "            allFilenamesV = vcat(allFilenamesV, file_path)\n",
    "            file_content = read(file_path, String)\n",
    "            file_contents = file_contents * \" \" * file_content\n",
    "\n",
    "            words_count = length(split(file_content))\n",
    "\n",
    "            date = replace(file, \"assessment-\" => \"\")\n",
    "            date = replace(date, \".txt\" => \"\")\n",
    "            date = Date.(date, \"yyyy-mm-dd\")\n",
    "            wordFrequencyToDateFrame = vcat(wordFrequencyToDateFrame, DataFrame(Date=date, Count=words_count))\n",
    "\n",
    "            allWordsInArticle[date] = words_count\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\")[\"path\"]), joinpath(@__DIR__, \"..\", \"1_data_preparation\"))\n",
    "text_processing = pyimport(\"text_preprocessing\")\n",
    "file_contents = text_processing.do_preprocessing(file_contents)\n",
    "\n",
    "\n",
    "using StatsBase\n",
    "wordFrequency = countmap(file_contents)\n",
    "wordFrequencyToDateFrame = DataFrame(wordFrequency)\n",
    "# set name for dataframe\n",
    "rename!(wordFrequencyToDateFrame)\n",
    "# wordFrequencyToDateFrame\n",
    "describe(wordFrequencyToDateFrame)\n",
    "\n",
    "\n",
    "using OrderedCollections\n",
    "\n",
    "od = OrderedDict(wordFrequency)\n",
    "od_vector = sort!(od; byvalue=true, rev=true)\n",
    "\n",
    "\n",
    "od_vector = first(od_vector, 100)\n",
    "od_vector = map(x -> [x.first, string(x.second)], od_vector)\n",
    "\n",
    "words_for_table = map(x -> x[1], od_vector)\n",
    "counts_for_table = map(x -> x[2], od_vector)\n",
    "\n",
    "Base.displaysize(x::DataFrame) = (100, 100)\n",
    "dadasdasd = DataFrame(Word=words_for_table, Count=counts_for_table)\n",
    "dadasdasd.Count = map(x -> parse(Int64, x), dadasdasd.Count)\n",
    "show(dadasdasd, allrows=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = Date.(\"2022-02-20\", \"yyyy-mm-dd\")\n",
    "end_date = Date.(Dates.now())\n",
    "\n",
    "b = bar(\n",
    "        collect(keys(allWordsInArticle)),\n",
    "        collect(values(allWordsInArticle)),\n",
    "        xlabel=\"\\nDate\\n\",\n",
    "        ylabel=\"Count\",\n",
    "        xlims=Dates.value.([start_date, end_date]),\n",
    "        xticks=:all,\n",
    "        title=\"\\nArticle words to date\\n\",\n",
    "        legend=true,\n",
    "        label=\"Count\",\n",
    "        grid=false,\n",
    "        size=(1200, 800),\n",
    "        \n",
    ")\n",
    "xticks!(b, Dates.value.([start_date:Dates.Month(1):end_date;]), Dates.format.([start_date:Dates.Month(1):end_date;], \"yyyy-mm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "bar(\n",
    "    dadasdasd.Word,\n",
    "    dadasdasd.Count,\n",
    "    xlabel=\"Word\",\n",
    "    ylabel=\"Count\",\n",
    "    title=\"Word frequency\",\n",
    "    label=\"Number of occurances\",\n",
    "    xrotation=90,\n",
    "    bar_width=0.3,\n",
    "    xticks=:all,\n",
    "    yticks=0:1000:50000,\n",
    "    yrotation=0,\n",
    "    yformatter=y -> @sprintf(\"%d\", y),\n",
    "    aspect_ratio=:none,\n",
    "    size=(1500, 1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each Dict in tfidf_keywords Vector of Dicts list all unique keys\n",
    "tfidf_keywords_keys = Set()\n",
    "for i in 1:length(tfidf_keywords)\n",
    "    for (word, value) in tfidf_keywords[i]\n",
    "        push!(tfidf_keywords_keys, word)\n",
    "    end\n",
    "end\n",
    "\n",
    "# create array from tfidf_keywords_keys\n",
    "tfidf_keywords_keys = collect(tfidf_keywords_keys)\n",
    "\n",
    "word_to_cum_tfidf_val = Dict{String, Float64}()\n",
    "for i in 1:length(tfidf_keywords_keys)\n",
    "    for (word, value) in tfidf_keywords[i]\n",
    "        if haskey(word_to_cum_tfidf_val, word)\n",
    "            word_to_cum_tfidf_val[word] += value\n",
    "        else\n",
    "            word_to_cum_tfidf_val[word] = value\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "println(word_to_cum_tfidf_val)\n",
    "\n",
    "\n",
    "wc = wordcloud(\n",
    "    word_to_cum_tfidf_val,\n",
    "    fonts=\"Tahoma\",\n",
    "    colors=:seaborn_dark,\n",
    "    density=0.5,\n",
    ") |> generate!\n",
    "# paint(wc, \"collection_wordcloud.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
